---
title: "Predict the manner of exercise"
author: "Ivan Kosyakov"
output: html_document
---

Load libraries:

```{r}
library (caret)
library (rattle)
```

# Cleansing data

To cleanse data we will delete variables which are not the raw measurements coming from the sensors, delete variables that have NAs, and delete variables with lot of blank values (interpreted as factors):

```{r}
dfTrain <- read.table ("pml-training.csv", sep=",", head = TRUE)
dfTrain <- dfTrain [,-c(1:7)] 
dfTrain <- dfTrain [,-c(4,7,10:12,14,15,17,18,20:29,43:52,
                        68:76,82,85:87,89,90,92:94,96:105,
                        120,123:125,127,128,130:132,134:143)]
dfTrain <- dfTrain [,-c(4:10,33:38,42:47,61:66)] 
```

Next we will delete 1 of each pair of strongly correlated variables. Let's see correlated variables first:

```{r}
M <- abs (cor (dfTrain[,-52]))
diag (M) <- 0
which (M > 0.8, arr.ind = T)
```

Now let's delete correlated variables:

```{r}
dfTrain <- dfTrain [,-c(1,2,7,9,17,20,24,27,28,32,45)] 
```

# Data standardization

Let's create model with standard values (mean = 0, sd = 1):

```{R}
preObj <- preProcess (dfTrain [,-41], method = c ("center", "scale"))
```

# Cross-validation of prediction model

Let's perform cross-validation of the Decision Trees models:

```{r}
successRatio <- vector ("numeric", length = 10)
for (i in 1:10) {
  set.seed (i)
  inTrain <- createDataPartition (y = dfTrain$classe, p = 0.9, list = FALSE)
  training <- dfTrain [inTrain,]
  testing <- dfTrain [-inTrain,]
  trainingS <- predict (preObj, training [,-41])
  trainingS$classe <- training$classe
  modFit <- train (classe ~ ., data = trainingS, method = 'rpart')
  prediction <- predict (modFit, newdata = testing)
  successRatio[i] <- sum (prediction == testing$classe) / dim (testing) [1]
}
mean (successRatio)
sd (successRatio)
mean (successRatio)/(1/6) # Compare with randow guess.
```

As a result of cross-validation we can see that for the models ratio of correct answers is 0.29  with standart deviation 0.0039 for 10 different models. Models are 1.72 times better than random guess.

# Create final prediction model

Now let's create prediction model using full source dataset.

```{r}
trainingS <- predict (preObj, dfTrain [,-41])
trainingS$classe <- dfTrain$classe
modFit <- train (classe ~ ., data = trainingS, method = 'rpart')
```

Here is graphical representation of the model:

```{r}
fancyRpartPlot (modFit$finalModel)
```

# Making predictions

Now let's load test dataset and make predictions:

```{r}
dfTesting <- read.table ("pml-testing.csv", sep=",", head = TRUE)
testingS <- predict (preObj, dfTesting)
prediction <- predict (modFit, newdata = testingS)
prediction
```
